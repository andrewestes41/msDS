count(df_black_r), NA, sum(df_black_r$sex=='Male'), sum(df_black_r$sex=='Female'), sum(df_black_r$c_charge_degree=='F'), sum(df_black_r$c_charge_degree=='M'), sum(df_black_r$juv_fel_count), sum(df_black_r$juv_misd_count), sum(df_black_r$juv_other_count),
count(df_white_r), NA, sum(df_white_r$sex=='Male'), sum(df_white_r$sex=='Female'), sum(df_white_r$c_charge_degree=='F'), sum(df_white_r$c_charge_degree=='M'), sum(df_white_r$juv_fel_count), sum(df_white_r$juv_misd_count), sum(df_white_r$juv_other_count)),
ncol=4)
colnames(counts) <- c("Black", "White", "Black_Recided", "White_Recided")
rownames(counts) <- c("Total", "Recided", "Male", "Female", "Felony", "Misdemeanor", "Juvenile Felony", "Juvenile Misdemeanor", "Juvenile Other")
kable(counts)
################### PART B
#Showing the age breakdown by race and age
histogram_black_scaled <- ggplot(df_black, aes(x = age, fill = two_year_recid)) +
geom_histogram(bins=10) +
ylim(0, 1150) +
xlim(10,80) +
theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = "none") +
ggtitle("Black Scaled")
histogram_white_scaled <- ggplot(df_white, aes(x = age, fill = two_year_recid)) +
geom_histogram(bins=10) +
ylim(0, 1150) +
xlim(10,80) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ggtitle("White Scaled")
histogram_black <- ggplot(df_black, aes(x = age, fill = two_year_recid)) +
geom_histogram(bins=10) +
theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = "none") +
ggtitle("Black")
histogram_white <- ggplot(df_white, aes(x = age, fill = two_year_recid)) +
geom_histogram(bins=10) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ggtitle("White")
grid.arrange(histogram_black, histogram_white, ncol=2)
#another way to look at the age/race breakdown
violin <- ggplot(df_r, aes(x = age, y=race, fill=race)) +
geom_violin(trim=FALSE)
violin + geom_boxplot(width=0.1, fill = "white")
#plotting different variables against the two_year_recid
marital <-
ggplot(df, aes(x=factor(marital_status), fill=factor(two_year_recid))) +
geom_histogram(stat="count") +
theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = "none")
marital_proportion <-
ggplot(df, aes(x=factor(marital_status), fill=factor(two_year_recid))) +
geom_histogram(stat = "count", position= "fill") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
decile <-
ggplot(df, aes(x=factor(decile_score), fill=factor(two_year_recid))) +
geom_bar(stat="count") +
theme(legend.position = "none")
decile_proportion <-
ggplot(df, aes(x=factor(decile_score), fill=factor(two_year_recid))) +
geom_histogram(stat = "count", position= "fill")
decile_text <-
ggplot(df, aes(x=factor(score_text), fill=factor(two_year_recid))) +
geom_histogram(stat = "count") +
theme(legend.position = "none")
decile_text_proportion <-
ggplot(df, aes(x=factor(score_text), fill=factor(two_year_recid))) +
geom_histogram(stat = "count", position= "fill")
marital + marital_proportion
decile + decile_proportion
decile_text + decile_text_proportion
#showing overall impact of age, time out of jail, and likelihood of recividism
model_end <- ggplot(df, aes(x=end, y=two_year_recid)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial))
model_priors <- ggplot(df, aes(x=priors_count, y=two_year_recid)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial))
model_age <- ggplot(df, aes(x=age, y=two_year_recid)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial))
model_decile <- ggplot(df, aes(x=decile_score, y=two_year_recid)) +
geom_point(alpha=.5) +
stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial))
model_end + model_priors
model_age + model_decile
#showing the relation between age and staying out of jail
model_end_age <- ggplot(df, aes(x=age, y=end)) +
geom_point(alpha=.5) +
stat_smooth(method="loess", se=TRUE)
model_end_age
#4
#finding NA values
colSums(is.na(df)) %>% as.data.frame()
df <- subset(df, select = -c(end)) #removing due to high correlation
#creating training/test datasets
set.seed(1234)
split <- sample(1:nrow(df), 0.75*floor(nrow(df)))
split.train <- df[split, ]
split.test <- df[-split, ]
split.train.numeric <- split.train %>%
mutate(two_year_recid = as.numeric(two_year_recid))
split.test.numeric <- split.train %>%
mutate(two_year_recid = as.numeric(two_year_recid))
table(split.train$race) %>%
kable()
fit.stats <- function(fit, test){
test$res <- test$two_year_recid - predict(fit, newdata = test)
rbind(test %>% group_by(race) %>%
summarize(Bias = -mean(res),
RMSE = sqrt(mean(res^2))),
test %>%
summarize(race = 'All',
Bias = -mean(res),
RMSE = sqrt(mean(res^2))))
}
# Log Loss as defined on the kaggle forum
LogLoss<-function(act, pred){
eps = 1e-15;
nr = length(pred)
pred = matrix(sapply( pred, function(x) max(eps,x)), nrow = nr)
pred = matrix(sapply( pred, function(x) min(1-eps,x)), nrow = nr)
ll = sum(act*log(pred) + (1-act)*log(1-pred))
ll = ll * -1/(length(act))
return(ll);
}
#5 - model 1 - steppwise regression
#Entire model
full.model <- lm(as.numeric(two_year_recid) ~., data = split.train)
summary(full.model)
stepAIC <- MASS::stepAIC
step.model <- stepAIC(full.model, direction = "both", trace = FALSE)
summary(step.model)
#creating confusion matrix
split.test$prob <- predict(step.model, split.test, type = "response")
split.test$recid <- ifelse(split.test$prob>=0.5, 1, 0)
library(Hmisc)
describe(split.test$race)
#list of races, 1,2,3
#dataframe
tab.step <- table(group=split.test$race, split.test$recid, split.test$two_year_recid)
tab.step2 <- table(split.test$recid, split.test$two_year_recid)
#plotting roc
plot(roc(split.test$two_year_recid, split.test$recid), col="red")
auc(roc(split.test$two_year_recid, split.test$recid), col="red")
#test dataset, create new column,
#graphing output
p <- split.test %>%
arrange(prob) %>%
mutate(rank = rank(prob),
Event = ifelse(prob >= 0/5, 'Jail', 'Free')) %>%
ggplot(aes(rank, prob)) +
geom_point(aes(color = Event)) +
geom_smooth(method = 'glm',
method.args = list(family = 'binomial'))
p
#using fit.stats function
fit.stats(step.model, split.test)
#5 - model 1 - steppwise regression
#Entire model
full.model <- lm(as.numeric(two_year_recid) ~., data = split.train)
summary(full.model)
stepAIC <- MASS::stepAIC
step.model <- stepAIC(full.model, direction = "both", trace = FALSE)
summary(step.model)
#creating confusion matrix
split.test$prob <- predict(step.model, split.test, type = "response")
split.test$recid <- ifelse(split.test$prob>=0.5, 1, 0)
library(Hmisc)
describe(split.test$race)
#list of races, 1,2,3
#dataframe
tab.step <- table(group=split.test$race, split.test$recid, split.test$two_year_recid)
tab.step2 <- table(split.test$recid, split.test$two_year_recid)
#plotting roc
plot(roc(split.test$two_year_recid, split.test$recid), col="red")
auc(roc(split.test$two_year_recid, split.test$recid), col="red")
#test dataset, create new column,
#graphing output
p <- split.test %>%
arrange(prob) %>%
mutate(rank = rank(prob),
Event = ifelse(prob >= 0/5, 'Jail', 'Free')) %>%
ggplot(aes(rank, prob)) +
geom_point(aes(color = Event)) +
geom_smooth(method = 'glm',
method.args = list(family = 'binomial'))
p
#using fit.stats function
#fit.stats(step.model, split.test)
#specificity and other stats
cm.step <- tab.step
accuracy.step <- sum(cm.step[1], cm.step[4]) / sum(cm.step[1:4])
precision.step <- cm.step[4] / sum(cm.step[4], cm.step[2])
sensitivity.step <- cm.step[4] / sum(cm.step[4], cm.step[3])
fscore.step <- (2 * (sensitivity.step * precision.step))/(sensitivity.step + precision.step)
specificity.step <- cm.step[1] / sum(cm.step[1], cm.step[2])
#graphing output
p <- split.test %>%
arrange(prob) %>%
mutate(rank = rank(prob),
Event = ifelse(prob >= 0.5, 'Jail', 'Free')) %>%
ggplot(aes(rank, prob)) +
geom_point(aes(color = Event)) +
geom_smooth(method = 'glm',
method.args = list(family = 'binomial'))
p
#5 - model 2 - naive bayes (https://www.r-bloggers.com/2021/04/naive-bayes-classification-in-r/)
bayes.model <- naive_bayes(two_year_recid ~ ., data = split.train, usekernel = T)
#5 - model 2 - naive bayes (https://www.r-bloggers.com/2021/04/naive-bayes-classification-in-r/)
bayes.model <- naive_bayes(as.factor(two_year_recid) ~ ., data = split.train, usekernel = T)
#5 - model 2 - naive bayes (https://www.r-bloggers.com/2021/04/naive-bayes-classification-in-r/)
bayes.model <- naive_bayes(as.factor(two_year_recid) ~ ., data = split.train, usekernel = T)
full.model <- lm(as.numeric(two_year_recid) ~., data = split.train)
#plot(bayes_model)
p <- predict(bayes.model, split.train, type="prob")
#confusion matrix train data
p1 <- predict(bayes_model, split.train)
#confusion matrix train data
p1 <- predict(bayes.model, split.train)
tab1.bayes <- table(p1, split.train$two_year_recid)
#5 - model 2 - naive bayes (https://www.r-bloggers.com/2021/04/naive-bayes-classification-in-r/)
bayes.model <- naive_bayes(as.factor(two_year_recid) ~ ., data = split.train, usekernel = T)
full.model <- lm(as.numeric(two_year_recid) ~., data = split.train)
#plot(bayes_model)
p <- predict(bayes.model, split.train, type="prob")
#confusion matrix train data
p1 <- predict(bayes.model, split.train)
tab1.bayes <- table(p1, split.train$two_year_recid)
#confusion matrix test data
p2 <- predict(bayes_model, split.test)
#5 - model 2 - naive bayes (https://www.r-bloggers.com/2021/04/naive-bayes-classification-in-r/)
bayes.model <- naive_bayes(as.factor(two_year_recid) ~ ., data = split.train, usekernel = T)
full.model <- lm(as.numeric(two_year_recid) ~., data = split.train)
#plot(bayes_model)
p <- predict(bayes.model, split.train, type="prob")
#confusion matrix train data
p1 <- predict(bayes.model, split.train)
tab1.bayes <- table(p1, split.train$two_year_recid)
#confusion matrix test data
p2 <- predict(bayes.model, split.test)
tab.bayes <- table(p2, split.test$two_year_recid)
tab.bayes
1 - sum(diag(tab2)) / sum(tab2)
#5 - model 2 - naive bayes (https://www.r-bloggers.com/2021/04/naive-bayes-classification-in-r/)
bayes.model <- naive_bayes(as.factor(two_year_recid) ~ ., data = split.train, usekernel = T)
full.model <- lm(as.numeric(two_year_recid) ~., data = split.train)
#plot(bayes_model)
p <- predict(bayes.model, split.train, type="prob")
#confusion matrix train data
p1 <- predict(bayes.model, split.train)
tab1.bayes <- table(p1, split.train$two_year_recid)
#confusion matrix test data
p2 <- predict(bayes.model, split.test)
tab.bayes <- table(p2, split.test$two_year_recid)
tab.bayes
1 - sum(diag(tab.bayes)) / sum(tab.bayes)
#just need to figure out how to group by race
fit.stats(bayes_model, split.test)
#5 - model 2 - naive bayes (https://www.r-bloggers.com/2021/04/naive-bayes-classification-in-r/)
bayes.model <- naive_bayes(as.factor(two_year_recid) ~ ., data = split.train, usekernel = T)
full.model <- lm(as.numeric(two_year_recid) ~., data = split.train)
#plot(bayes_model)
p <- predict(bayes.model, split.train, type="prob")
#confusion matrix train data
p1 <- predict(bayes.model, split.train)
tab1.bayes <- table(p1, split.train$two_year_recid)
#confusion matrix test data
p2 <- predict(bayes.model, split.test)
tab.bayes <- table(p2, split.test$two_year_recid)
tab.bayes
1 - sum(diag(tab.bayes)) / sum(tab.bayes)
#just need to figure out how to group by race
#fit.stats(bayes_model, split.test)
#specificity and other stats
cm.bayes <- tab.bayes
accuracy.bayes <- sum(cm.bayes[1], cm.bayes[4]) / sum(cm.bayes[1:4])
precision.bayes <- cm.bayes[4] / sum(cm.bayes[4], cm.bayes[2])
sensitivity.bayes <- cm.bayes[4] / sum(cm.bayes[4], cm.bayes[3])
fscore.bayes <- (2 * (sensitivity.bayes * precision.bayes))/(sensitivity.bayes + precision.bayes)
specificity.bayes <- cm.bayes[1] / sum(cm.bayes)
specificity.bayes
#5 - model 3 - linear discrimant analysis https://www.r-bloggers.com/2021/05/linear-discriminant-analysis-in-r/
lda <- MASS::lda
#install.packages("klaR")
library(klaR)
lda.model <- lda(two_year_recid ~., split.train)
lda.predict <- predict(lda.model, split.train)
#partimat(two_year_recid ~., data = split.train, method = 'lda')
lda.predict.class <- predict(linear, split.test.numeric)$class
lda.predict.class <- predict(lda.model, split.test.numeric)$class
#5 - model 3 - linear discrimant analysis https://www.r-bloggers.com/2021/05/linear-discriminant-analysis-in-r/
lda <- MASS::lda
#install.packages("klaR")
library(klaR)
lda.model <- lda(two_year_recid ~., split.train)
lda.predict <- predict(lda.model, split.train)
#partimat(two_year_recid ~., data = split.train, method = 'lda')
lda.predict.class <- predict(lda.model, split.test.numeric)$class
tab.lda <- table(lda.predict.class, split.test.numeric$two_year_recid)
tab.lda
#fit.stats(lda.predict, split.test)
#specificity and other stats
cm.lda <- tab.lda
accuracy.lda <- sum(cm.lda[1], cm.lda[4]) / sum(cm.lda[1:4])
precision.lda <- cm.lda[4] / sum(cm.lda[4], cm.lda[2])
sensitivity.lda <- cm.lda[4] / sum(cm.lda[4], cm.lda[3])
fscore.lda <- (2 * (sensitivity.lda * precision.lda))/(sensitivity.lda + precision.lda)
specificity.lda <- cm.lda[1] / sum(cm.lda)
specificity.lda
#running logistic regression
logit <- glm(two_year_recid ~ ., data = split.train, family = "binomial")
#prepping for table output
race.list <- list("African-American" = "African-American",
"Caucasian" = "Caucasian",
"All" = c("African-American", "Caucasian"))
detach(package:Hmisc)
display.stats <- function(test){
map_dfr(race.list, ~ test %>% filter(race %in% .x) %>%
summarize(Accuracy = mean(two_year_recid==predict),
Sensitivity = sum(two_year_recid=="TRUE" & predict=="TRUE")/sum(two_year_recid=="TRUE"),
Specificity = sum(two_year_recid=="FALSE" & predict=="FALSE")/sum(two_year_recid=="FALSE")),
.id="Race") %>%
kable()
}
step.results <- split.test %>%
mutate(predict = factor(predict(step.model, newdata=split.test, type="response") > .50)) %>%
display.stats()
bayes.results <- split.test %>%
mutate(predict = (predict(bayes.model, newdata=split.test, type="prob") > .50)) %>%
display.stats()
logit.results <- split.test %>%
mutate(predict = (predict(logit, newdata=split.test, type="response") > .50)) %>%
display.stats()
step.results
bayes.results
#lda.results
logit.results
step.results
bayes.results
step.results
bayes.results
#lda.results
logit.results
plot.housingComparison <- ggplot(data = df,
aes(x = Year)) +
geom_line(aes(y = n_medianHomePrice/1000), color="blue") +
geom_line(aes(y = n_medianFamilyIncome/1000), color="red") +
xlab("Year") +
ylab("US Dollars in Thousands") +
ggtitle("Median Home Price (blue) and Median Family Income (red)")
library(tidyverse)
library(readxl)
library(lubridate)
#importing data
original.df <- read_excel("inflationAnalysis.xlsx")
df <- original.df
head(df)
plot.housingComparison <- ggplot(data = df,
aes(x = Year)) +
geom_line(aes(y = n_medianHomePrice/1000), color="blue") +
geom_line(aes(y = n_medianFamilyIncome/1000), color="red") +
xlab("Year") +
ylab("US Dollars in Thousands") +
ggtitle("Median Home Price (blue) and Median Family Income (red)")
plot.housingComparison
plot.housingComparison <- ggplot(data = df,
aes(x = Year)) +
geom_line(aes(y = n_medianHomePrice/1000), color="blue", size = 1.1) +
geom_line(aes(y = n_medianFamilyIncome/1000), color="red", suze = 1.1) +
xlab("Year") +
ylab("US Dollars in Thousands") +
ggtitle("Median Home Price (blue) and Median Family Income (red)")
plot.housingComparison
plot.miscComparison <- ggplot(data = df,
aes(x = Year)) +
geom_line(aes(y = n_medianHomePrice/1000), color="blue", size = 1.1) +
geom_line(aes(y = n_medianFamilyIncome/1000), color="red", size = 1.1) +
geom_line(aes(y = n_GDP/100), color="green", size = 1.1) +
xlab("Year") +
ylab("US Dollars in Thousands") +
ggtitle("Median Home Price (Blue), Median Family Income (Red), and Nominal GDP (green)") +
labs(caption = "GDP is in a different scale (100,000 Billions) than Home Price and Family Income (1000s)")
library(tidyverse)
library(readxl)
library(lubridate)
#importing data
original.df <- read_excel("inflationAnalysis.xlsx")
df <- original.df
# head(df)
library(tidyverse)
library(readxl)
library(lubridate)
#importing data
original.df <- read_excel("inflationAnalysis.xlsx")
df <- original.df
# head(df)
View(df)
dfComp <- df %>%
filter(row_number()==1 & row_number()==39)
View(dfComp)
dfComp <- df %>%
filter(row_number()==1 | row_number()==39)
View(dfComp)
dfComp <- rbind(dfComp, dfComp[1, ] / dfComp[2, ] )
dfComp <- df %>%
filter(row_number()==1 | row_number()==39)
dfComp <- rbind(dfComp, dfComp[1, ] / dfComp[2, ] )
View(dfComp)
dfComp <- df %>%
filter(row_number()==1 | row_number()==38)
dfComp <- rbind(dfComp, dfComp[1, ] / dfComp[2, ])
View(df)
dfComp <- df %>%
filter(row_number()==1 | row_number()==39) %>%
subset(select = -c(n_tuition))
dfComp <- df %>%
filter(row_number()==1 | row_number()==39) %>%
subset(select = -c(n_tuition, r_CEOtoTop.01Earners, r_CEOtoWorkerCompensationRatio, r_medianHouseholdIncome))
dfComp <- rbind(dfComp, dfComp[1, ] / dfComp[2, ])
View(dfComp)
dfComp <- df %>%
filter(row_number()==1 | row_number()==39) %>%
subset(select = -c(n_tuition, r_CEOtoTop.01Earners, r_CEOtoWorkerCompensationRatio, r_medianHouseholdIncome, inflationCPI))
dfComp <- rbind(dfComp, dfComp[2, ] / dfComp[1, ])
dfComp <- round(rbind(dfComp, dfComp[2, ] / dfComp[1, ]), 2)
library(titanic)
library(tidyverse)
library(readxl)
library(lubridate)
library(pscl)
library(lmtest)
library(geepack)
library(flexmix)
library(lme4)
library(bpr)
library(bayesplot)
library(tidybayes)
library(broom.mixed)
library(rstanarm)
library(bayesrules)
#importing data
original.df <- read.csv("final_pit_only.csv")
df <- original.df
head(df)
library(tidyverse)
library(readxl)
library(lubridate)
library(pscl)
library(lmtest)
library(geepack)
library(flexmix)
library(lme4)
library(bpr)
library(bayesplot)
library(tidybayes)
library(broom.mixed)
library(rstanarm)
library(bayesrules)
#importing data
original.df <- read.csv("final_pit_only.csv")
setwd("C:/Users/andre/OneDrive/Desktop")
library(tidyverse)
library(readxl)
library(lubridate)
library(pscl)
library(lmtest)
library(geepack)
library(flexmix)
library(lme4)
library(bpr)
library(bayesplot)
library(tidybayes)
library(broom.mixed)
library(rstanarm)
library(bayesrules)
#importing data
original.df <- read.csv("final_pit_only.csv")
df <- original.df
head(df)
cols <- c("DriverNumberCat", "CompoundCat", "FreshTyre", "Stint", "TeamCat", "Year", "DriverCat", "TrackStatusCat", "GridPosition", "Position", "RaceCat", "FreshTyreCat")
df[cols] <- lapply(df[cols], factor)  ## as.factor() could also be used
head(df)
#https://cran.r-project.org/web/packages/pscl/vignettes/countreg.pdf
library(sandwich)
pois <- glm(LapNumber ~ ., data = df, family = poisson)
summary(pois)
coeftest(pois, vcov = sandwich) #inference function wald test; sandwich covariance matrix estimator
qpois <- glm(LapNumber ~ ., data = df, family = quasipoisson)
summary(qpois)
nbin <- MASS::glm.nb(LapNumber ~ ., data = df)
summary(nbin)
#cannot do hurdle or zip to to non-zero minimum count
summary(pois)
coeftest(pois, vcov = sandwich) #inference function wald test; sandwich covariance matrix estimator
qpois <- glm(LapNumber ~ ., data = df, family = quasipoisson)
summary(qpois)
summary(pois)
summary(pois)
coeftest(pois, vcov = sandwich) #inference function wald test; sandwich covariance matrix estimator
nbin <- MASS::glm.nb(LapNumber ~ ., data = df)
nbin <- MASS::glm.nb(LapNumber ~ ., data = df)
summary(nbin)
summary(nbin)
m.ex <- geeglm(LapNumber ~ .,
data = df,
id = interaction(cols, ),
family = poisson,
corstr = "exchangeable")
flex <- flexmix(LapNumber ~ .,
data = df,
k = 19,
model = FLXMRglm(family = "poisson"))
#https://www.bayesrulesbook.com/chapter-12.html
df %>%
group_by(cut(TyreLife,3), FreshTyre) %>%
summarize(mean = mean(LapNumber), var = var(LapNumber))
books_negbin_sim <- stan_glm(
LapNumber ~ .,
data = df, family = neg_binomial_2,
prior_intercept = normal(0, 2.5, autoscale = TRUE),
prior = normal(0, 2.5, autoscale = TRUE),
prior_aux = exponential(1, autoscale = TRUE),
chains = 4, iter = 2 * 1000, seed = 84735)
